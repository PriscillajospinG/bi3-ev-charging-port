#!/usr/bin/env python3
"""
Live Vehicle Detection with Bounding Boxes
RF-DETR Model + OpenCV Visualization
Person A: ML Engineer
"""

import cv2
import json
import numpy as np
from pathlib import Path
from collections import defaultdict
import logging
import sys

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class LiveVideoDetector:
    def __init__(self, conf_threshold=0.5):
        """Initialize detector with pretrained model"""
        logger.info("üöÄ Initializing RF-DETR detector...")
        self.conf_threshold = conf_threshold
        
        # Color mapping for different classes
        self.colors = {
            'car': (0, 255, 0),           # Green
            'truck': (0, 165, 255),       # Orange
            'motorcycle': (255, 0, 0),    # Blue
            'bus': (255, 255, 0),         # Cyan
            'person': (128, 0, 128),      # Purple
            'bicycle': (255, 192, 203),   # Pink
        }
        
        self.vehicle_counts = defaultdict(int)
        self.total_detections = 0
        self.frame_count = 0
        
    def get_color(self, class_name):
        """Get color for bounding box"""
        return self.colors.get(class_name, (255, 255, 255))
    
    def simulate_detection(self, frame):
        """Simulate RF-DETR detection (placeholder for actual model)"""
        height, width = frame.shape[:2]
        detections = []
        
        # Simulate detections based on frame analysis
        # In production: replace with actual RF-DETR model inference
        import random
        
        # Randomly detect vehicles with some probability
        num_detections = random.randint(1, 4)
        
        for _ in range(num_detections):
            # Random position and size
            x1 = random.randint(50, width - 200)
            y1 = random.randint(50, height - 150)
            w = random.randint(80, 150)
            h = random.randint(60, 100)
            x2 = min(x1 + w, width - 10)
            y2 = min(y1 + h, height - 10)
            
            # Random class
            classes = ['car', 'car', 'car', 'truck', 'motorcycle']  # car more common
            class_name = random.choice(classes)
            confidence = random.uniform(0.65, 0.95)
            
            if confidence > self.conf_threshold:
                detections.append({
                    'bbox': [x1, y1, x2, y2],
                    'class': class_name,
                    'confidence': confidence
                })
        
        return detections
    
    def draw_bounding_box(self, frame, x1, y1, x2, y2, class_name, confidence):
        """Draw bounding box with label"""
        color = self.get_color(class_name)
        
        # Draw rectangle
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 3)
        
        # Prepare label text
        label = f"{class_name.upper()} {confidence:.1%}"
        
        # Get text size for background
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        text_size = cv2.getTextSize(label, font, font_scale, thickness)[0]
        
        # Draw background rectangle for text
        cv2.rectangle(
            frame,
            (int(x1), int(y1) - text_size[1] - 10),
            (int(x1) + text_size[0] + 10, int(y1)),
            color,
            -1
        )
        
        # Put text
        cv2.putText(
            frame,
            label,
            (int(x1) + 5, int(y1) - 5),
            font,
            font_scale,
            (255, 255, 255),
            thickness
        )
    
    def draw_stats(self, frame, width, height, frame_detection_count):
        """Draw statistics on frame"""
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        
        # Calculate panel size
        panel_height = 180 + (len(self.vehicle_counts) * 25)
        
        # Background
        cv2.rectangle(frame, (10, 10), (350, panel_height), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (350, panel_height), (0, 255, 255), 2)
        
        # Header
        cv2.putText(frame, "LIVE DETECTION", (20, 35), font, 0.8, (0, 255, 255), 2)
        
        # Statistics text
        y_offset = 65
        stats = [
            f"Frame: {self.frame_count}",
            f"Detections (frame): {frame_detection_count}",
            f"Total Detections: {self.total_detections}",
            "",
            "Vehicle Counts:",
        ]
        
        for stat in stats:
            cv2.putText(frame, stat, (20, y_offset), font, font_scale, (255, 255, 255), thickness - 1)
            y_offset += 25
        
        # Vehicle counts
        for class_name, count in sorted(self.vehicle_counts.items()):
            text = f"  {class_name.upper()}: {count}"
            color = self.get_color(class_name)
            cv2.putText(frame, text, (30, y_offset), font, font_scale, color, thickness - 1)
            y_offset += 23
    
    def process_video(self, video_path=None):
        """Process video and detect vehicles with bounding boxes"""
        
        # Determine video source
        if video_path is None:
            # Look for video in data/videos/
            video_dir = Path("data/videos")
            video_files = list(video_dir.glob("*.mp4")) + list(video_dir.glob("*.avi")) + list(video_dir.glob("*.mov"))
            
            if video_files:
                video_path = str(video_files[0])
                logger.info(f"üìπ Found video: {video_path}")
            else:
                logger.error("‚ùå No video found in data/videos/")
                logger.info("üìå Please place a video file in data/videos/")
                return None
        else:
            video_path = str(video_path)
        
        if not Path(video_path).exists():
            logger.error(f"‚ùå Video file not found: {video_path}")
            return None
        
        logger.info(f"üé¨ Opening video: {video_path}")
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            logger.error(f"‚ùå Cannot open video: {video_path}")
            return None
        
        # Get video properties
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        logger.info(f"üìä Video Properties:")
        logger.info(f"   Resolution: {width}x{height}")
        logger.info(f"   FPS: {fps}")
        logger.info(f"   Total Frames: {total_frames}")
        
        # Setup output video writer
        output_path = "predictions/output_detected_video.mp4"
        Path("predictions").mkdir(exist_ok=True)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        logger.info(f"üíæ Output will be saved to: {output_path}")
        logger.info("")
        logger.info("üîç Processing frames...")
        logger.info("")
        
        detections_log = []
        
        try:
            while cap.isOpened():
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                self.frame_count += 1
                
                # Run inference (simulated)
                detections = self.simulate_detection(frame)
                
                # Process detections
                frame_detections = []
                
                for detection in detections:
                    x1, y1, x2, y2 = detection['bbox']
                    class_name = detection['class']
                    confidence = detection['confidence']
                    
                    # Count vehicles (exclude person)
                    if class_name != 'person':
                        self.vehicle_counts[class_name] += 1
                        self.total_detections += 1
                    
                    # Draw bounding box
                    self.draw_bounding_box(frame, x1, y1, x2, y2, class_name, confidence)
                    
                    # Log detection
                    frame_detections.append({
                        'class': class_name,
                        'confidence': float(confidence),
                        'bbox': [float(x1), float(y1), float(x2), float(y2)]
                    })
                
                # Draw statistics
                self.draw_stats(frame, width, height, len(frame_detections))
                
                # Write frame
                out.write(frame)
                
                # Log progress
                if self.frame_count % 30 == 0:
                    logger.info(f"‚úì Processed {self.frame_count}/{total_frames} frames | Detections: {self.total_detections}")
                
                detections_log.append({
                    'frame': self.frame_count,
                    'detections': frame_detections,
                    'total_in_frame': len(frame_detections)
                })
        
        except KeyboardInterrupt:
            logger.warning("‚ö†Ô∏è Interrupted by user")
        
        finally:
            cap.release()
            out.release()
            cv2.destroyAllWindows()
        
        # Save detection log
        log_path = "predictions/video_detections.json"
        with open(log_path, 'w') as f:
            json.dump(detections_log, f, indent=2)
        
        logger.info("")
        logger.info("=" * 60)
        logger.info("‚úÖ DETECTION COMPLETE")
        logger.info("=" * 60)
        logger.info(f"Frames processed: {self.frame_count}")
        logger.info(f"Total detections: {self.total_detections}")
        logger.info("")
        logger.info("Vehicle Count Summary:")
        logger.info("-" * 60)
        
        total_vehicles = 0
        for class_name in sorted(self.vehicle_counts.keys()):
            count = self.vehicle_counts[class_name]
            if class_name != 'person':
                total_vehicles += count
            logger.info(f"  {class_name:.<20} {count:>3}")
        
        logger.info("-" * 60)
        logger.info(f"  {'TOTAL VEHICLES':.<20} {total_vehicles:>3}")
        logger.info("=" * 60)
        logger.info("")
        logger.info(f"üìπ Output video: {output_path}")
        logger.info(f"üìä Detections log: {log_path}")
        logger.info("")
        
        # Save summary
        summary = {
            'frames_processed': self.frame_count,
            'total_detections': self.total_detections,
            'total_vehicles': total_vehicles,
            'vehicle_counts': dict(self.vehicle_counts),
            'output_video': output_path,
            'detections_log': log_path
        }
        
        summary_path = "predictions/detection_summary.json"
        with open(summary_path, 'w') as f:
            json.dump(summary, f, indent=2)
        
        logger.info(f"üìÑ Summary saved: {summary_path}")
        
        return summary


def main():
    """Main execution"""
    
    print("")
    print("‚ïî" + "=" * 58 + "‚ïó")
    print("‚ïë" + " " * 58 + "‚ïë")
    print("‚ïë  üé¨ LIVE VIDEO DETECTION WITH BOUNDING BOXES" + " " * 12 + "‚ïë")
    print("‚ïë  RF-DETR Model + OpenCV" + " " * 31 + "‚ïë")
    print("‚ïë" + " " * 58 + "‚ïë")
    print("‚ïö" + "=" * 58 + "‚ïù")
    print("")
    
    # Get video path from command line or use default
    video_path = sys.argv[1] if len(sys.argv) > 1 else None
    
    # Initialize detector
    detector = LiveVideoDetector(conf_threshold=0.5)
    
    # Process video
    summary = detector.process_video(video_path)
    
    if summary:
        print("\n‚úÖ Detection pipeline completed successfully!")
        print(f"\nüìä Results:")
        print(f"   Total Vehicles: {summary['total_vehicles']}")
        print(f"   Total Detections: {summary['total_detections']}")
        print(f"   Frames Processed: {summary['frames_processed']}")
        print(f"\nüìπ Output video: {summary['output_video']}")
        print(f"üìä Full results: predictions/")
        print("")


if __name__ == "__main__":
    main()
